---
title: 'Support Vector Machine'
date: 2024-08-18
permalink: /posts/2024/08/SVM/
tags:
  - Machine Learning
  - Classification
---

### Perceptron Learning Algorithm (PLA)
Let
\begin{equation}
F(x) = \mbox{sign} ( \beta^T x)
\end{equation}
with zero-loss function 
1. find a mistake of $$\beta_t$$ called $$(x_{n(t)}, A_{n(t)})$$
$$
\begin{aligned}
\mbox{sign} (\beta^T x) \neq A_{n(t)}
\end{aligned}
$$
3. (try to) correct the mistake by 
$$
\begin{aligned}
\beta_{t+1}=\beta_t + A_{n(t)} x_{n(t)}
\end{aligned}
$$
until there are no more mistakes.

### Support Vector Machine (SVM)

#### Hard Margin SVM
The smallest distance from each class to the separating hyperplane $$\beta^T x$$ is called the margin. This problem can be expressed as follows
$$
\begin{aligned}
\max_{\beta,b} (\mbox{margin}) = \max_{\beta,b} \left( \frac{2}{||\beta||} \right)\ \mbox{or}\ \min_{\beta,b} ||\beta||^2
\end{aligned}
$$
subject to 
$$
\begin{aligned}
\left\{ \begin{array}{ll} \beta^T x+b\geq 1 & i:A_i=+1\\
\beta^T x+b \leq -1 & i:A_i=-1
\end{array} \right. 
\end{aligned}
$$
This is a convex optimization problem. 

### Optimization and Lagrangian
(Generic) optimization problem on $$x$$
\begin{aligned}
\min\              & f_0(x) \\
\mbox{subject to}\ & f_i(x) \leq 0\ i=1,...,m \\
				   & h_i(x) = 0\ i=1,...,p
\end{aligned}
Let $$p^{\star}$$ be the optimal value. Ideally, we would want an unconstrained problem 
$$
\begin{aligned}
\min\ f_0(x) + \sum_{i=1}^m I_- (f_i(x)) + \sum_{i=1}^p I_0 (h_i(x)),
\end{aligned}
$$
where 
$$
\begin{aligned}
I_-(u) = \left\{ \begin{array}{ll}
         0 & \mbox{if $u \leq 0$};\\
         \infty & \mbox{if $u > 0$}.\end{array} \right.
\end{aligned}
$$
and $$I_0(u)$$ is the indicator of 0.

#### Lower bound interpretation of Lagrangian
The Lagrangian L is a lower bound on the original problem
$$
\begin{aligned}
L(x,\lambda,\nu) = f_0(x)+\sum_{i=1}^m \lambda_i f_i(x) + \sum_{i=1}^p \nu_i h_i(x)
\end{aligned}
$$
The vectors $$\lambda$$ and $$\nu$$ are called Lagrange multipliers or dual variables. To ensure a lower bound, we require $$\lambda \succeq 0$$

#### Lagrange dual: lower bound on optimum $$p^{\star}$$
The Lagrange dual function: minimize Lagrangian when $$\lambda \succeq 0$$ and $$f_i(x) \leq 0$$, Lagrange dual function is
$$
\begin{aligned}
g(\lambda,\nu) = \inf_x L(x,\lambda,\nu)
\end{aligned}
$$
We now give a formal proof that Lagrange dual function $$g(\lambda,\nu)$$ lower bound $$p^{\star}$$.

Notably, assume $$\tilde{x}$$ is feasible, i.e. $$f_i(\tilde{x})\leq 0$$, $$h_i(x)=0$$, $$\lambda \succeq 0$$. Then
$$
\begin{aligned}
\sum_{i=1}^m \lambda_i f_i(\tilde{x})+\sum_{i=1}^p \nu_i h_i(\tilde{x}) \leq 0
\end{aligned}
$$
Thus, 
$$
\begin{aligned}
g(\lambda,\nu) &= \inf_x \left( f_0(x)+\sum_{i=1}^m \lambda_i f_i(x) + \sum_{i=1}^p \nu_i h_i(x)  \right) \\
& \leq f_0(\tilde{x}) + \sum_{i=1}^m \lambda_i f_i(\tilde{x}) + \sum_{i=1}^p \nu_i h_i(\tilde{x}) \\
& \leq f_0(\tilde{x})
\end{aligned}
$$
This holds for every feasible $$\tilde{x}$$, hence lower bound holds.

 
#### Best lower bound maximizes the dual
Best lower bound $$g(\lambda,\nu)$$ on the optimal solution $$p^{\star}$$ of (Generic) optimization problem: 
Lagrange dual problem 
$$
\begin{aligned}
\max\ &g(\lambda,\nu) \\
\mbox{subject to}\ &\lambda \succeq 0
\end{aligned}
$$
Dual optimal: solution $$(\lambda^*,\nu^*)$$ maximizing dual, $$d^{\star}$$ is optimal value. 

a. Weak duality always holds: $$d^{\star} \leq p^{\star}$$
b. Strong duality (does not always hold, condition given later): $$d^{\star} = p^{\star}$$

#### A consequence of strong duality

Assume primal is equal to the dual.
a. $$x^{\star}$$ solution of original problem (minimum of $$f_0$$ under constraints)
b. $$(\lambda^{\star},\nu^{\star})$$ solutions to dual 
$$
\begin{aligned}
f_0(x^{\star}) &= g(\lambda^{\star},\nu_{\star}) \\
&= \inf_x \left( f_0(x)+\sum_{i=1}^m \lambda^{\star}_i f_i(x) + \sum_{i=1}^p \nu^{\star}_i h_i(x)  \right) \\
&\leq f_0(x^{\star}) + \sum_{i=1}^m \lambda^{\star}_i f_i(x^{\star}) + \sum_{i=1}^p \nu^{\star}_i h_i(x^{\star}) \\
&\leq f_0(x^{\star})
\end{aligned}
$$
satisfies $$\lambda^{\star} \succeq 0$$, $$f_i(x^{\star}) \leq 0$$ and $$h_i(x^{\star})=0.$$

#### Complementary Slackness
From the previous section, 
$$
\begin{aligned}
\sum_{i=1}^m \lambda^{\star}_i f_i(x^{\star})=0
\end{aligned}
$$
which is the condition of complementary slackness. This means
$$
\begin{aligned}
\lambda^{\star}_i >0 &\Longrightarrow f_i(x^{\star})=0,\\
f_i(x^{\star})<0 &\Longrightarrow \lambda^{\star}_i =0
\end{aligned}
$$

#### KKT conditions for global optimum
Assume functions $$f_i$$, $$h_i$$ are differentiable and have strong duality. Since $x^{\star}$ minimizes $$L(x,\lambda^{\star},\nu^{\star})$$, derivative at $$x^{\star}$$ is zero, 
$$
\begin{aligned}
\triangledown f_0(x^{\star})+ \sum_{i=1}^m \lambda^{\star}_i \triangledown f_i(x^{\star}) + \sum_{i=1}^p \nu^{\star}_i \triangledown h_i(x^{\star})=0
\end{aligned}
$$
KKT conditions definition: we are at global optimum, $$(x,\lambda,\nu)=(x^{\star},\lambda^{\star},\nu^{\star})$$ when (a) strong duality holds, and (b)
$$
\begin{aligned}
f_i(x) &\leq 0,\ i=1,...,m \ \mbox{(primal feasibility)} \\
h_i(x) &=    0,\ i=1,...,p \ \mbox{(primal feasibility)} \\
\lambda_i &\geq 0,\ i=1,...,m \ \mbox{(dual feasibility)} \\
\lambda_i f_i(x)&=0,\ i=1,...,m \ \mbox{(complementary slackness)}
\end{aligned}
$$

In summary: if 
1. primal problem convex and 
2. constraint functions satisfy Slater's conditions

then strong duality holds. 
If in addition
3. function $$f_i$$, $$h_i$$ is differentiable

then KKT conditions are necessary and sufficient for optimality. 

### Hard Margin SVM
Smallest distance from each class to the separating hyperplane $\beta^T x$ is called the margin. This problem can be expressed as follows
$$
\begin{aligned}
\max_{\beta,b} (\mbox{margin}) = \max_{\beta,b} \left( \frac{2}{||\beta||} \right)\ \mbox{or}\ \min_{\beta,b} ||\beta||^2
\end{aligned}
$$
subject to 
$$
\begin{aligned}
\left\{ \begin{array}{ll} \beta^T x+b\geq 1 & i:A_i=+1\\
\beta^T x+b \leq -1 & i:A_i=-1
\end{array} \right. 
\end{aligned}
$$
we can rewrite subject to 
$$
\begin{aligned}
A_i (\beta x_i+b) \geq 1
\end{aligned}
$$

### Soft SVM (with errors allowed)
Allowed error points within the margin, or even on the wrong side of the decision boundary.
$$
\begin{aligned}
\min_{\beta,b} \left( \frac{1}{2}||\beta||^2 + C\sum_{i=1}^n I\left[y_i\left(\beta^T x_i+b\right)<0\right] \right)
\end{aligned}
$$
Where $$C$$ controls the tradeoff between maximum margin and loss. Replace with a convex upper bound: 
$$
\begin{aligned}
\min_{\beta,b} \left( \frac{1}{2}||\beta||^2 + C\sum_{i=1}^n \theta \left[y_i\left(\beta^T x_i+b\right)<0\right]) \right)
\end{aligned}
$$
with hinge loss,
$$ 
\begin{aligned}
\theta(\alpha)=(1-\alpha)_{+} = \left\{ \begin{array}{ll}
         1-\alpha & \mbox{if $1-\alpha > 0$};\\
         0 & \mbox{otherwise}.\end{array} \right. 
\end{aligned}
$$

Substituting in the hinge loss, we get
$$
\begin{aligned}
\min_{\beta,b} \left( \frac{1}{2}||\beta||^2 + C\sum_{i=1}^n \theta \left[y_i\left(\beta^T x_i+b\right)<0\right] \right)
\end{aligned}
$$
rewrite inequality constraints
$$
\begin{aligned}
\min f_0(\beta,b,\xi)=\min_{\beta,b,\xi} \left( \frac{1}{2} ||\beta||^2+C\sum_{i=1}^n \xi_i \right)
\end{aligned}
\$$
subject to 
$$
\begin{aligned}
&\xi_i \geq 0 \\
&y_i \left( \beta^Tx_i+b \right) \geq 1-\xi_i
\end{aligned}
$$
Let $$f_i(\beta,b,\xi)=1-\xi_i-\left( \beta^Tx_i+b \right) \leq 0\ i=1,...,n$$

- Each of $$f_0,f_1,...,f_n$$ are convex.
- Slater's condition holds. 

Thus strong duality holds, that the problem is differentiable, hence the KKT conditions hold at the global optimum. 

#### Support Vector Machine: Lagrangian
The Lagrangian: 
$$
\begin{aligned}
L(\beta,b,\xi,\alpha,\lambda)=\frac{1}{2}||\beta||^2 + C\sum_{i=1}^n \xi_i + \sum_{i=1}^n \alpha_i \left( 1-\xi_i-y_i\left( \beta^Tx_i+b \right) \right) + \sum_{i=1}^n \lambda_i (-\xi_i)
\end{aligned}
$$
with dual variable constraints 
$$
\begin{aligned}
\alpha \geq 0,\ \lambda \geq 0
\end{aligned}
$$
Minimize w.r.t the primal variable $$\beta$$, $$b$$, and $$\xi.$$

Derivative w.r.t. $\beta$:
$$
\begin{aligned}
\frac{\partial L}{\partial \beta}=\beta-\sum_{i=1}^n \alpha_iy_ix_i=0 \Longrightarrow \beta=\sum_{i=1}^n \alpha_iy_ix_i
\end{aligned}
$$
Derivative w.r.t. $$b$$:
$$
\begin{aligned}
\frac{\partial L}{\partial b}=\sum_{i} y_i \alpha_i=0.
\end{aligned}
$$
Derivative w.r.t. $$\xi_i$$:
$$
\begin{aligned}
\frac{\partial L}{\partial \xi_i}=C-\alpha_i-\lambda_i=0 \Longrightarrow \alpha_i=C-\lambda_i
\end{aligned}
$$
Noting that $$\lambda_i \geq 0$$
$$
\begin{aligned}
\alpha_i \leq C
\end{aligned}
$$

Now use complementary slackness:
Non-margin SVs: $$\alpha_i=C \neq 0$$:
- We have $$1-\xi_i=y_i\left(\beta^Tx_i+b \right)$$
- Also, from condition $$\alpha_i=C-\lambda_i$$, we have $$\lambda_i=0$$ (hence can have $$\xi_i>0$$)

Margin SVs: $$0<\alpha_i<C$$:

- We have $$1-\xi_i=y_i\left(\beta^Tx_i+b \right)$$
- This time $$\alpha_i=C-\lambda_i$$, we have $$\lambda_i \neq 0$, hence $\xi_i=0$$

Non SVs: $$\alpha_i=0$$
- This time we can have $$y_i\left(\beta^Tx_i+b \right)>1-\xi$$
- From $$\alpha_i=C-\lambda_i$$, we have $$\lambda_i \neq 0$$, hence $$\xi_i=0$$

#### The Support Vectors
We observe
- The solution is sparse: points that are not on the margin, or "margin errors", have $$\alpha_i=0$$
- The support vectors: only those points on the decision boundary, or which are margin errors, contribute. 
- Influence of the non-margin SVs is bounded since their weight cannot exceed $C$.

#### Support Vector Machine: Dual function
Thus, our goal is to maximize the dual 
$$
\begin{aligned}
g(\alpha,\nu)&=\frac{1}{2}||\beta||^2 + C\sum_{i=1}^n \xi_i + \sum_{i=1}^n \alpha_i \left( 1-\xi_i-y_i\left( \beta^Tx_i+b \right) \right) + \sum_{i=1}^n \lambda_i (-\xi_i) \\
&=\sum_{i=1}^m \alpha_i - \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j y_i y_j x_i^T x_j
\end{aligned}
$$
subject to 
$$
\begin{aligned}
0 \leq \alpha_i \leq C,\ \sum_{i=1}^n \alpha_i y_i =0
\end{aligned}
$$
This is a quadratic program. 

#### Sequential Minimal Optimization Algorithm (SMO)
The SMO (sequential minimal optimization) algorithm, due to John Platt, gives an efficient way of solving the dual problem arising from the derivation of the SVM. 

Coordinate ascent: 
Consider trying to solve the unconstrained optimization problem
$$
\begin{aligned}
\max_{\alpha} f(\alpha_1,...,\alpha_m)
\end{aligned}
$$
Loop until convergence: 
For $$i = 1,...,m$$ 
 $$\hat{\alpha}_i= \arg \max_{\alpha_i} f(\alpha_1,..., \alpha_{i-1}, \hat{\alpha}_i, \alpha_{i+1},..., \alpha_{m}).$$



Letâ€™s say we have a set of $$\alpha_i$$'s that satisfy the constraints. Now, suppose we want to hold $\alpha_2,...,\alpha_m$ fixed, and take a coordinate ascent step and re-optimize the objective with respect to $$\alpha_1$$. Can we make any progress? The answer is No because 
$$
\begin{aligned}
\alpha_1 y_1=-\sum_{i=2}^m \alpha_i y_i
\end{aligned}
$$
Hence, $$\alpha_1$$ is exactly determined by the other $$\alpha_i$$'s, and if we were to hold $$\alpha_2,...,\alpha_m$$ fixed.
Thus, if we want to update some subject of the $\alpha_i$'s, we must update at least two of them simultaneously in order to keep satisfying the constraints. From constraint, we require that
$$
\begin{aligned}
\alpha_1 y_1 + \alpha_2 y_2 = \sum_{i=3}^m \alpha_i  y_i
\end{aligned}
$$

Since the right hand side is fixed (as we've fixed $$\alpha_3,...,\alpha_m$$), we can just let it be denoted by some constant $\zeta$:
$$
\begin{aligned}
\alpha_1 y_1 + \alpha_2 y_2 = \zeta
\end{aligned}
$$

we can also write $$\alpha_1$$ as a function of $$\alpha_2$$:
$$
\begin{aligned}
\alpha_1=y_1 \cdot (\zeta-\alpha_2 y_2)
\end{aligned}
$$
Hence, the objective $$L(\alpha)$$ can be written
$$
\begin{aligned}
L(\alpha_1,\alpha_2,...,\alpha_m)=L(y_1(\zeta-\alpha_2 y_2),\alpha_2,...,\alpha_m)
\end{aligned}
$$
this can also be expressed in the form $$a\alpha_2^2 + b\alpha_2 + c$$ for some appropriate $$a$$, $$b$$, and $$c$$.  If we ignore the "box" constraints (or, equivalently, that $$L \leq \alpha_2 \leq H$$), then we can easily maximize this quadratic function by setting its derivative to zero and solving.  let $$\alpha^{new,unclipped}_2$$ denote the resulting value of $$\alpha_2$$. Because $$\alpha^{new,unclipped}_2$$ lies in $$[L,H]$$ interval
$$
\begin{aligned}
\alpha_2^{new} = \left\{ \begin{array}{ll}
         H & \mbox{if $\alpha^{new,unclipped}_2 > H$};\\
         \alpha^{new,unclipped}_2 & \mbox{if $L \leq \alpha^{new,unclipped}_2 \leq H$};\\
         L & \mbox{if $\alpha^{new,unclipped}_2 < L$}.\end{array} \right. 
\end{aligned}
$$
we can update $$\alpha_1^{new}$$, simultaneously. 





